/*
Copyright 2025.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package controller

import (
	"context"
	"fmt"
	"time"

	"github.com/go-logr/logr"
	"k8s.io/apimachinery/pkg/runtime"
	ctrl "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"
	"sigs.k8s.io/controller-runtime/pkg/log"

	monitoringv1 "github.com/devzero-inc/zxporter/api/v1"
	metricsv1 "k8s.io/metrics/pkg/client/clientset/versioned"

	"github.com/devzero-inc/zxporter/internal/collector"
	"github.com/devzero-inc/zxporter/internal/transport"
	"github.com/devzero-inc/zxporter/internal/util"
	"k8s.io/client-go/kubernetes"
)

// CollectionPolicyReconciler reconciles a CollectionPolicy object
type CollectionPolicyReconciler struct {
	client.Client
	Scheme            *runtime.Scheme
	Log               logr.Logger
	K8sClient         *kubernetes.Clientset
	CollectionManager collector.CollectionManager
	Sender            transport.Sender
	IsRunning         bool
}

//+kubebuilder:rbac:groups=monitoring.devzero.io,resources=collectionpolicies,verbs=get;list;watch;create;update;patch;delete
//+kubebuilder:rbac:groups=monitoring.devzero.io,resources=collectionpolicies/status,verbs=get;update;patch
//+kubebuilder:rbac:groups=monitoring.devzero.io,resources=collectionpolicies/finalizers,verbs=update
//+kubebuilder:rbac:groups=core,resources=pods,verbs=get;list;watch
//+kubebuilder:rbac:groups=core,resources=pods/status,verbs=get
//+kubebuilder:rbac:groups=core,resources=nodes,verbs=get;list;watch
//+kubebuilder:rbac:groups=core,resources=nodes/status,verbs=get

// Reconcile is part of the main kubernetes reconciliation loop which aims to
// move the current state of the cluster closer to the desired state.
// TODO(user): Modify the Reconcile function to compare the state specified by
// the CollectionPolicy object against the actual cluster state, and then
// perform operations to make the cluster state reflect the state specified by
// the user.
//
// For more details, check Reconcile and its Result here:
// - https://pkg.go.dev/sigs.k8s.io/controller-runtime@v0.19.0/pkg/reconcile
func (r *CollectionPolicyReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
	logger := log.FromContext(ctx)
	logger.Info("Reconciling CollectionPolicy", "request", req)

	// Fetch the CollectionPolicy instance
	var policy monitoringv1.CollectionPolicy
	if err := r.Get(ctx, req.NamespacedName, &policy); err != nil {
		return ctrl.Result{}, client.IgnoreNotFound(err)
	}

	// Initialize collection system if not already running
	if !r.IsRunning {
		return r.initializeCollectors(ctx, &policy)
	}

	// TODO: Handle updates to policy if already running (update using env also)

	return ctrl.Result{}, nil
}

// initializeCollectors sets up and starts the collectors based on policy
func (r *CollectionPolicyReconciler) initializeCollectors(ctx context.Context, policy *monitoringv1.CollectionPolicy) (ctrl.Result, error) {
	logger := r.Log.WithName("initialize")

	// Convert excluded pods from policy format to collector format
	var excludedPods []collector.ExcludedPod
	for _, pod := range policy.Spec.Exclusions.ExcludedPods {
		excludedPods = append(excludedPods, collector.ExcludedPod{
			Namespace: pod.Namespace,
			Name:      pod.PodName,
		})
	}

	// Parse update frequency from policy (default to 10s if not specified)
	updateInterval := 10 * time.Second
	if policy.Spec.Policies.Frequency != "" {
		parsedInterval, err := time.ParseDuration(policy.Spec.Policies.Frequency)
		if err != nil {
			logger.Error(err, "Failed to parse update frequency, using default",
				"default", updateInterval)
		} else {
			updateInterval = parsedInterval
		}
	}

	// Create collection config
	collectionConfig := &collector.CollectionConfig{
		Namespaces:   policy.Spec.TargetSelector.Namespaces,
		ExcludedPods: excludedPods,
		BufferSize:   policy.Spec.Policies.BufferSize,
	}

	// Create collection manager if not already created
	if r.CollectionManager == nil {
		r.CollectionManager = collector.NewCollectionManager(
			collectionConfig,
			r.K8sClient,
			logger.WithName("collection-manager"),
		)
	}

	// Create metrics client for container resource usage
	config := ctrl.GetConfigOrDie()
	metricsClient, err := metricsv1.NewForConfig(config)
	if err != nil {
		logger.Error(err, "Failed to create metrics client, container resource collection will be disabled")
	}

	// Create and register pod collector
	podCollector := collector.NewPodCollector(
		r.K8sClient,
		policy.Spec.TargetSelector.Namespaces,
		excludedPods,
		logger,
	)

	if err := r.CollectionManager.RegisterCollector(podCollector); err != nil {
		logger.Error(err, "Failed to register pod collector")
		return ctrl.Result{}, err
	}

	// Create and register container resource collector if metrics client is available
	containerResourceCollector := collector.NewContainerResourceCollector(
		r.K8sClient,
		metricsClient,
		policy.Spec.TargetSelector.Namespaces,
		excludedPods,
		updateInterval,
		logger,
	)

	if err := r.CollectionManager.RegisterCollector(containerResourceCollector); err != nil {
		logger.Error(err, "Failed to register container resource collector")
		return ctrl.Result{}, err
	}

	// Create and register node collector
	nodeCollector := collector.NewNodeCollector(
		r.K8sClient,
		metricsClient,
		[]string{}, // You may want to add excluded nodes from policy
		updateInterval,
		logger,
	)

	if err := r.CollectionManager.RegisterCollector(nodeCollector); err != nil {
		logger.Error(err, "Failed to register node collector")
		return ctrl.Result{}, err
	}

	// Create and register node metrics collector
	// For node metrics, we use a longer interval (60s by default)
	nodeMetricsInterval := updateInterval * 6 // Default to 60s if updateInterval is 10s
	if nodeMetricsInterval < 60*time.Second {
		nodeMetricsInterval = 60 * time.Second // Minimum 60s
	}

	// Extract excluded nodes from policy if available
	var excludedNodes []string
	if policy.Spec.Exclusions.ExcludedLabels != nil {
		// we might want to implement logic to find nodes with these labels
		// For now, we'll just use an empty list
	}

	nodeMetricsCollector := collector.NewNodeMetricsCollector(
		r.K8sClient,
		excludedNodes,
		nodeMetricsInterval,
		logger,
	)

	if err := r.CollectionManager.RegisterCollector(nodeMetricsCollector); err != nil {
		logger.Error(err, "Failed to register node metrics collector")
		return ctrl.Result{}, err
	}

	// Start the collection manager
	if err := r.CollectionManager.StartAll(ctx); err != nil {
		logger.Error(err, "Failed to start collection manager")
		return ctrl.Result{}, err
	}

	// Start processing collected resources
	go r.processCollectedResources(ctx)

	r.IsRunning = true
	logger.Info("Successfully started collectors")

	return ctrl.Result{}, nil
}

// processCollectedResources reads from collection channel and forwards to sender
func (r *CollectionPolicyReconciler) processCollectedResources(ctx context.Context) {
	logger := r.Log.WithName("processor")
	logger.Info("Starting to process collected resources")

	resourceChan := r.CollectionManager.GetCombinedChannel()

	for {
		select {
		case <-ctx.Done():
			logger.Info("Context done, stopping processor")
			return
		case resource, ok := <-resourceChan:
			if !ok {
				logger.Info("Resource channel closed, stopping processor")
				return
			}

			// Send the raw resource directly to Dakr
			if err := r.Sender.Send(ctx, resource.ResourceType, resource.Object); err != nil {
				logger.Error(err, "Failed to send resource to Dakr",
					"resourceType", resource.ResourceType,
					"eventType", resource.EventType,
					"key", resource.Key)
			} else {
				logger..Info("Sent resource to Dakr",
					"resourceType", resource.ResourceType,
					"eventType", resource.EventType,
					"key", resource.Key)
			}
		}
	}
}

// SetupWithManager sets up the controller with the Manager.
func (r *CollectionPolicyReconciler) SetupWithManager(mgr ctrl.Manager) error {
	// Set up basic components
	r.Log = util.NewLogger("controller")

	// Create a Kubernetes clientset
	config := mgr.GetConfig()
	clientset, err := kubernetes.NewForConfig(config)
	if err != nil {
		return fmt.Errorf("failed to create kubernetes clientset: %w", err)
	}
	r.K8sClient = clientset

	// Create a simple Dakr client (replace with actual implementation later)
	dakrClient := transport.NewSimpleDakrClient(r.Log)
	r.Sender = transport.NewDirectDakrSender(dakrClient, r.Log)

	return ctrl.NewControllerManagedBy(mgr).
		For(&monitoringv1.CollectionPolicy{}).
		Complete(r)
}
